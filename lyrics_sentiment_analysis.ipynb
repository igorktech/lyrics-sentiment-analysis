{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Collect data\n",
    "# Cleanup data\n",
    "# WordCloud\n",
    "# Sentiment (Vader) -> check rougness of lyrics per year/ check number of abcense words\n",
    "# topic modelling\n",
    "# Web wiki db -> plot map of relation between birth place and artists in top rank\n",
    "# Train NN T5 ->< try to explain lyrics -> explain all text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "The operation couldn’t be completed. Unable to locate a Java Runtime that supports apt.\r\n",
      "Please visit http://www.java.com for information on installing Java.\r\n",
      "\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --quiet\n",
    "!pip install sklearn --quiet\n",
    "!pip install datasets --quiet\n",
    "!apt install git-lfs --quiet\n",
    "!pip install transformers --quiet\n",
    "!pip install sentencepiece --quiet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas --quiet\n",
    "!pip install numpy --quiet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: billboard.py in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (7.0.0)\r\n",
      "Requirement already satisfied: requests>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from billboard.py) (2.28.2)\r\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from billboard.py) (4.11.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->billboard.py) (2.3.2.post1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.2.1->billboard.py) (2022.12.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.2.1->billboard.py) (1.26.14)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.2.1->billboard.py) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.2.1->billboard.py) (3.4)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 --quiet\n",
    "!pip install lyricsgenius --quiet\n",
    "!pip install billboard.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/johnwmillr/LyricsGenius.git --quiet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.21.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import dotenv\n",
    "import os\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Import Genious access token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "load_dotenv(os.path.join(os.getcwd(),'.env'))\n",
    "GENIOUS_ACCESS_TOKEN = os.environ.get('GENIOUS_ACCESS_TOKEN')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:100% !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from IPython.display import HTML, display\n",
    "from bs4 import BeautifulSoup\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "import lyricsgenius as genius\n",
    "import billboard\n",
    "import sys\n",
    "import re\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# import string\n",
    "# from nltk.stem import PorterStemmer\n",
    "from datetime import datetime, date, timedelta\n",
    "# from wordcloud import WordCloud\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "# import spacy\n",
    "# from collections import Counter\n",
    "# from os import path\n",
    "# from PIL import Image\n",
    "# from keras.models import model_from_json\n",
    "# import pickle\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import random\n",
    "from tqdm.auto import tqdm, trange\n",
    "from huggingface_hub import notebook_login\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "% config InlineBackend.figure_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def disable_pandas_warnings():\n",
    "    import warnings\n",
    "    warnings.resetwarnings()  # Maybe somebody else is messing with the warnings system?\n",
    "    warnings.filterwarnings('ignore')  # Ignore everything\n",
    "    # ignore everything does not work: ignore specific messages, using regex\n",
    "    warnings.filterwarnings('ignore', '.*A value is trying to be set on a copy of a slice from a DataFrame.*')\n",
    "    warnings.filterwarnings('ignore', '.*indexing past lexsort depth may impact performance*')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "disable_pandas_warnings()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Collecting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days // 7)):\n",
    "        yield start_date + timedelta(n*7)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def collect_songs_from_billboard_each_day(start_date_str, end_date_str, chart_name='hot-100', table_path = None,to_csv = False):\n",
    "    start_date = datetime.strptime(\n",
    "        start_date_str, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "\n",
    "    columns = [\"Rank\",\n",
    "                    \"Song Title\",\n",
    "                    \"Artist\",\n",
    "                    \"Date\",\n",
    "                    \"Year\"]\n",
    "    dataset = pd.DataFrame(columns = columns, data = [])\n",
    "    if to_csv:\n",
    "        dataset.to_csv(table_path,index=False)\n",
    "\n",
    "    sys.stdout.write(\n",
    "        \"\\r\" + \"Collecting Songs from \" + start_date_str + \" to \" + end_date_str + \" via https://www.billboard.com\")\n",
    "    sys.stdout.flush()\n",
    "    for single_date in tqdm(daterange(start_date, end_date)):\n",
    "        print(single_date.strftime('%Y-%m-%d'))\n",
    "        chart = billboard.ChartData(chart_name, date=single_date.strftime('%Y-%m-%d'))\n",
    "        for song in chart:\n",
    "            row = {\n",
    "                \"Rank\": song.rank,\n",
    "                \"Song Title\": song.title,\n",
    "                \"Artist\": song.artist,\n",
    "                \"Date\": single_date.strftime('%Y-%m-%d'),\n",
    "                \"Year\": single_date.strftime('%Y')\n",
    "            }\n",
    "            if to_csv:\n",
    "                pd.DataFrame([row]).to_csv(table_path, mode='a',index=False, header=False)\n",
    "            else:\n",
    "                dataset = dataset.append(row, ignore_index=True)  #pd.concat([dataset,pd.DataFrame(row)],ignore_index=True)#\n",
    "    if not to_csv:\n",
    "        return dataset\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_songs = collect_songs_from_billboard_each_day('2003-02-17', '2023-02-17',table_path='all_songs_20.csv',to_csv = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "all_songs = pd.read_csv(\"all_songs_20.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "    Rank                 Song Title                              Artist  \\\n0      1                 All I Have  Jennifer Lopez Featuring LL Cool J   \n1      2                 In Da Club                             50 Cent   \n2      3                  Mesmerize           Ja Rule Featuring Ashanti   \n3      4           Bump, Bump, Bump                      B2K & P. Diddy   \n4      5             Cry Me A River                   Justin Timberlake   \n..   ...                        ...                                 ...   \n65    66              No Letting Go                        Wayne Wonder   \n66    67               Make It Clap  Busta Rhymes Featuring Spliff Star   \n67    68                 Can't Stop               Red Hot Chili Peppers   \n68    69  What Happened To That Boy               Baby Featuring Clipse   \n69    70               A.D.I.D.A.S.       Killer Mike Featuring Big Boi   \n\n          Date  Year  \n0   2003-02-17  2003  \n1   2003-02-17  2003  \n2   2003-02-17  2003  \n3   2003-02-17  2003  \n4   2003-02-17  2003  \n..         ...   ...  \n65  2003-02-17  2003  \n66  2003-02-17  2003  \n67  2003-02-17  2003  \n68  2003-02-17  2003  \n69  2003-02-17  2003  \n\n[70 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Song Title</th>\n      <th>Artist</th>\n      <th>Date</th>\n      <th>Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>All I Have</td>\n      <td>Jennifer Lopez Featuring LL Cool J</td>\n      <td>2003-02-17</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>In Da Club</td>\n      <td>50 Cent</td>\n      <td>2003-02-17</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Mesmerize</td>\n      <td>Ja Rule Featuring Ashanti</td>\n      <td>2003-02-17</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Bump, Bump, Bump</td>\n      <td>B2K &amp; P. Diddy</td>\n      <td>2003-02-17</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Cry Me A River</td>\n      <td>Justin Timberlake</td>\n      <td>2003-02-17</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>66</td>\n      <td>No Letting Go</td>\n      <td>Wayne Wonder</td>\n      <td>2003-02-17</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>67</td>\n      <td>Make It Clap</td>\n      <td>Busta Rhymes Featuring Spliff Star</td>\n      <td>2003-02-17</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>68</td>\n      <td>Can't Stop</td>\n      <td>Red Hot Chili Peppers</td>\n      <td>2003-02-17</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>69</td>\n      <td>What Happened To That Boy</td>\n      <td>Baby Featuring Clipse</td>\n      <td>2003-02-17</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>70</td>\n      <td>A.D.I.D.A.S.</td>\n      <td>Killer Mike Featuring Big Boi</td>\n      <td>2003-02-17</td>\n      <td>2003</td>\n    </tr>\n  </tbody>\n</table>\n<p>70 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_songs.head(70)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "all_songs[\"Artist\"][all_songs['Artist'] == \"Jackson 5\"] = \"The Jackson 5\"\n",
    "all_songs[\"Artist\"][all_songs['Artist'] == \"Beatles\"] = \"The Beatles\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "all_songs.drop_duplicates(subset=['Artist','Song Title']).to_csv('unique_songs_20.csv', mode='a',index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "api = genius.Genius(GENIOUS_ACCESS_TOKEN,timeout = 5, sleep_time=0.015, verbose=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2023-03-18 15:38:32.176995\n",
      "\n",
      "Completed at 2023-03-18 15:38:32.176995\n",
      "Total time to collect: 5:20:57.880854\n"
     ]
    }
   ],
   "source": [
    "all_songs = pd.read_csv(\"unique_songs_20.csv\")\n",
    "\n",
    "GENIOUS_CSV = 'all_songs_data_new.csv'\n",
    "columns = [ \"Year\",\n",
    "        \"Rank\",\n",
    "        \"Song Title\",\n",
    "        \"Artist\",\n",
    "        \"Primary Artists\",\n",
    "        \"Lyrics\",\n",
    "        \"Song URL\",\n",
    "        \"Song id\",\n",
    "        \"Song stats\",\n",
    "        \"Song annotations\"]\n",
    "dataset = pd.DataFrame(columns = columns, data = [])\n",
    "dataset.to_csv(GENIOUS_CSV,index=False)\n",
    "\n",
    "\n",
    "all_song_data = pd.DataFrame()\n",
    "start_time = datetime.now()\n",
    "print(\"Started at {}\".format(start_time))\n",
    "for i in range(0, len(all_songs)):\n",
    "    rolling_pct = int((i / len(all_songs)) * 100)\n",
    "    # print(str(rolling_pct) + \"% complete.\" + \" Collecting Record \" + str(i) + \" of \" +\n",
    "    #       str(len(all_songs)) + \". Year \" + str(all_songs.iloc[i]['Year']) + \".\" + \" Currently collecting \" +\n",
    "    #       all_songs.iloc[i]['Song Title'] + \" by \" + all_songs.iloc[i]['Artist'] + \" \" * 50, end=\"\\r\")\n",
    "    song_title = all_songs.iloc[i]['Song Title']\n",
    "    song_title = re.sub(\" and \", \" & \", song_title)\n",
    "    artist_name = all_songs.iloc[i]['Artist']\n",
    "    artist_name = re.sub(\" and \", \" & \", artist_name)\n",
    "\n",
    "    try:\n",
    "        song = api.search_song(song_title, artist=artist_name)\n",
    "        primary_artists = song.primary_artist\n",
    "        song_lyrics = re.sub(\"\\n\", \" \", song.lyrics)  #Remove newline breaks, we won't need them.\n",
    "        song_url = song.url\n",
    "        song_id = song.id\n",
    "        song_stats = song.stats\n",
    "        song_annotations = api.song_annotations(song.id)\n",
    "    except:\n",
    "        primary_artists = \"null\"\n",
    "        song_lyrics = \"null\"\n",
    "        song_url = \"null\"\n",
    "        song_id = \"null\"\n",
    "        song_stats = 'null'\n",
    "        song_annotations = 'null'\n",
    "\n",
    "    row = {\n",
    "        \"Year\": all_songs.iloc[i]['Year'],\n",
    "        \"Rank\": all_songs.iloc[i]['Rank'],\n",
    "        \"Song Title\": all_songs.iloc[i]['Song Title'],\n",
    "        \"Artist\": all_songs.iloc[i]['Artist'],\n",
    "        \"Primary Artists\": primary_artists,\n",
    "        \"Lyrics\": song_lyrics,\n",
    "        \"Song URL\": song_url,\n",
    "        \"Song id\": song_id,\n",
    "        \"Song stats\": song_stats,\n",
    "        \"Song annotations\": song_annotations\n",
    "    }\n",
    "    pd.DataFrame([row]).to_csv(GENIOUS_CSV, mode='a',index=False, header=False)\n",
    "    # all_song_data = all_song_data.append(row, ignore_index=True)\n",
    "end_time = datetime.now()\n",
    "print(\"\\nCompleted at {}\".format(start_time))\n",
    "print(\"Total time to collect: {}\".format(end_time - start_time))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "song = api.search_song('THE STORY OF ALISHER', artist='Oxxxymiron')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Не хочу никому давать копаться в своей голове\\n Не хочу, сука\\n Боюсь, что раскопают чё-то там', [['Это слова Алишера в интервью Ютуб-каналу «Вписка».\\n\\nВ клипе к треку скит заканчивается “погружением” в голову моргенштерноголового монстра. Копание в мусорке, раздражённая женщина в бигуди и другие образы представляются при помощи панорамной съёмки — подсказка что мы находимся в голове Моргенштерна и смотрим на мир его глазами.']]), ('Никого кругом, листья падают в бассейн', [['После переезда за границу Моргенштерн приобрёл дом с бассейном в Дубае. Впоследствии он снял несколько клипов и интервью у этого бассейна.\\n\\n\\n\\nКадр из клипа на «Double Cup»\\n\\n\\n\\n\\nВозможно, эту строчку стоит рассматривать как поэтическую аллегорию об одиночестве и застое и отсылку к цитате из романа Великий Гэтсби:\\n\\nЯ нынче собираюсь спустить воду в бассейне, мистер Гэтсби. Скоро листья начнут опадать, а от них всегда беда с трубами. — Только не сегодня, — ответил Гэтсби. Он с каким-то виноватым видом повернулся ко мне. — Знаете, старина, я ведь так за всё лето и не поплавал в бассейне.\\n\\nОсушение бассейна символизировало закат жизни главного героя — впавшего в крайность культуры потребления кутилы, стремившегося добиться общепринятой мечты признанием мифической версии себя. Этот образ отлично ложится и на Алишера.']]), ('Чисто мэшапы', [['В конце 2021 года, в районе выхода «КТО УБИЛ МАРКА» и третьего микстейпа Мирона, в рунете форсились мэшапы, в которых совмещали матерную считалочку Оксимирона из его баттла с Джонибоем. Её искажённый фрагмент был использован и в дисс-треке Моргенштерна «Я УБИЛ МАРКА»\\n\\nhttps://youtu.be/NPdPnHq2BOs?t=57\\n\\nОтсылка к мэшапам использована для сравнения дисса оппонента с фан-работой, компиляцией, не отличающейся глубокой трансформацией или переосмыслением исходного материала.']]), ('Таблетки, вебка да экран и кровь на салфетке', [['Мирон считает, что Моргенштерн даже из суицида попытался бы сделать шоу. 2 куплета назад Окси уже обращался к этой теме:\\n\\nЯ не лезу в твою личную жизнь, ты её вываливаешь\\nКончится внимание — ты умрёшь перед камерами']]), ('Это славянская словесность', [['Намёк на то, что распространитель (а может быть и сочинитель) истории про «педиков в кровати» это Слава КПСС.\\n\\nПодтверждено самим Славой на его стриме с обзором дисса.']]), ('Извини, тут далеко на одних тачках не уедешь', [['Творчестве Алишера сильно акцентируется на автомобилях: он въезжал на сцену на своём «новом Мерине», записал трек «12», посвящённый его Бентли, выпустил совместный с Арутом «BUGATTI».\\n\\nТреки, связанные с его машинами, стали одними из его главных бэнгеров и принесли ему основную известность: «Новый Мерин» и «Cadillac».\\n\\nМирон говорит Алишеру о том, что для того, чтобы стать артистом, которого запомнят надолго, нужно записывать не только посвящённые автомобилям кратковременные хиты.']]), ('По-моему, из дома звёздная болезнь\\n Ведь твоя ма не верит в тебя, но верит в гуманоидов\\n А про лирических героев\\n Малдер и Скалли донесли\\n Что человечек всё не спрыгивает с астероидов', [['В выпуске Ксении Собчак про Моргенштерна и его свадьбу она пообщалась в том числе и с матерью Алишера — Мариной Валеевой.\\n\\nКогда Собчак задала ей вопрос про странный танец в масках инопланетян на свадьбе Алишера и Дилары, Марина ответила ей, что уверена в существовании внеземной жизни:\\n\\nЯ знаю, что они есть. Но я не хочу об этом говорить, а то подумают, что мама тоже накурилась. Я бы очень хотела встретиться с физиками, с Илоном Маском… Это не эзотерика, это не религия, это физика. То, что я вижу, например, в воздухе, я хочу об этом поговорить. Каждый ребёнок с рождения видит это в постоянстве, эти заряды электрические.\\n\\nМалдер и Скалли — культовые персонажи сериала Секретные материалы, посвящённого отделу ФБР по расследованию паранормальных явлений.\\n\\nСтрока про астероиды имеет двойной смысл (со стероидов/с астероидов): это и предположение о том, что Моргенштерн употребляет стероиды для того, чтобы лучше выглядеть, и отсылка к знаменитой повести Антуана де Сент-Экзюпери «Маленький принц» — её герой родился на одном астероиде и в течение жизни перемещался на другие, чтобы познать тайны Вселенной.']]), ('С собою старый хит, как прикид — «Cadillac»', [['Мирон говорит о том, что уже достаточно долгое время Моргенштерн не может превзойти успех своего хита 2020 года «Cadillac». Он «таскает» его с собой повсюду, потому что сейчас у него не получается создать что-то популярнее. «Cadillac» остаётся самым прослушиваемым треком Алишера на стриминговых платформах, а страница этой песни на Genius — самой просматриваемой из всего его каталога (всё это примерно на одном уровне с «Cristal & МОЁТ» и «ICE» — тоже хитами 2020 года).\\n\\n\\n\\n\\n\\nИгра слов: вторую часть строчки можно услышать и по-другому:\\n\\nКак при Kid Cudi лак\\n\\nЭто небольшая отсылка к строчке выше:\\n\\nФальшивая улыбка под ноготочки\\n\\nКид Кади — американский рэпер, часто появляющийся на публике в ярких и необычных образах: в платье или с накрашенными ногтями.\\n\\n\\n\\nМоргенштерн тоже красил ногти — на обложке своего трека «ICE», например.']]), ('Чарты — всё, назад в ИзиРеп', [['#ИзиРеп — рубрика, которая принесла Моргенштерну огромную популярность на Ютубе.\\n\\nhttps://www.youtube.com/watch?v=JQT5omjl2wM\\n\\nТеперь, когда он больше не появляется в чартах, Мирон предлагает ему полноценно вернуться к истокам. Что примечательно, за некоторое время до выхода этого дисса, 20 ноября 2022 года, Алишер записал совместный выпуск #ИзиРеп с Лидой — первый за 3 года.\\n\\nhttps://www.youtube.com/watch?v=iO7iwczm898']]), ('Ты потерял нюх\\n Клоун задумался о своём наследии\\n Так вот оно: «На твоей кровати ебутся педики!»\\n Со смыслом нахуй!', [['Алишер в интервью Дудю на вопрос «как ты понимаешь, что хит, а что нет?» ответил: «Не знаю, у меня чуйка какая-то на это».\\n\\nТеперь, после выхода альбома Моргенштерна LAST ONE, который не снискал популярности в чартах, Мирон высмеивает этот ответ, мол за четыре года с момента выхода «Новый Мерин» у Алишера знатно упали цифры — он потерял нюх на хиты. Например, хит конца 2020 года «Cristal & МОЁТ» держался в чарте около полугода, а хит с его последнего альбома LAST ONE —  «SHEIKH», не продержался и двух месяцев.\\n\\nМирон как бы подводит итог карьеры Моргенштерна: всё его музыкальное наследие — глупые строчки, которые разберут на мемы и пофорсят непродолжительное количество времени. Как, например, строчки из его дисса «Я УБИЛ МАРКА»:\\n\\nИнтегральная гипербола ректальной кибернетики (Со смыслом нахуй)\\nНа твоей кровати ебутся педики (Это факт)']])]\n"
     ]
    }
   ],
   "source": [
    "# for i in song.to_dict():\n",
    "print(api.song_annotations(song.id))\n",
    "    # print(api.song_comments(song.to_dict()['id']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "    Year  Rank                                   Song Title  \\\n6   2022     7                                    Kill Bill   \n7   2022     8                                Feliz Navidad   \n8   2022     9                                    Anti-Hero   \n9   2022    10                                       Unholy   \n10  2022    11  The Christmas Song (Merry Christmas To You)   \n\n                    Artist                    Primary Artists  \\\n6                      SZA                       SZA, 0 songs   \n7           Jose Feliciano            José Feliciano, 0 songs   \n8             Taylor Swift              Taylor Swift, 0 songs   \n9   Sam Smith & Kim Petras    Sam Smith & Kim Petras, 0 songs   \n10           Nat King Cole  The Nat “King” Cole Trio, 0 songs   \n\n                                               Lyrics  \\\n6   TranslationsEspañolPortuguêsItalianoTürkçeDeut...   \n7   Feliz Navidad Lyrics[Letra de \"Feliz Navidad\"]...   \n8   TranslationsPortuguêsEspañolTürkçeFrançais中文Ne...   \n9   TranslationsFrançaisEspañolNederlandsDeutschال...   \n10  The Christmas Song (Merry Christmas to You) (O...   \n\n                                             Song URL  Song id  \\\n6             https://genius.com/Sza-kill-bill-lyrics  8616820   \n7   https://genius.com/Jose-feliciano-feliz-navida...   623111   \n8    https://genius.com/Taylor-swift-anti-hero-lyrics  8434253   \n9   https://genius.com/Sam-smith-and-kim-petras-un...  8302862   \n10  https://genius.com/The-nat-king-cole-trio-the-...  1717793   \n\n                                           Song stats  \n6   Stats('unreviewed_annotations, concurrents, ho...  \n7     Stats('unreviewed_annotations, hot, pageviews')  \n8   Stats('unreviewed_annotations, concurrents, ho...  \n9   Stats('unreviewed_annotations, concurrents, ho...  \n10    Stats('unreviewed_annotations, hot, pageviews')  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Rank</th>\n      <th>Song Title</th>\n      <th>Artist</th>\n      <th>Primary Artists</th>\n      <th>Lyrics</th>\n      <th>Song URL</th>\n      <th>Song id</th>\n      <th>Song stats</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>2022</td>\n      <td>7</td>\n      <td>Kill Bill</td>\n      <td>SZA</td>\n      <td>SZA, 0 songs</td>\n      <td>TranslationsEspañolPortuguêsItalianoTürkçeDeut...</td>\n      <td>https://genius.com/Sza-kill-bill-lyrics</td>\n      <td>8616820</td>\n      <td>Stats('unreviewed_annotations, concurrents, ho...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2022</td>\n      <td>8</td>\n      <td>Feliz Navidad</td>\n      <td>Jose Feliciano</td>\n      <td>José Feliciano, 0 songs</td>\n      <td>Feliz Navidad Lyrics[Letra de \"Feliz Navidad\"]...</td>\n      <td>https://genius.com/Jose-feliciano-feliz-navida...</td>\n      <td>623111</td>\n      <td>Stats('unreviewed_annotations, hot, pageviews')</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2022</td>\n      <td>9</td>\n      <td>Anti-Hero</td>\n      <td>Taylor Swift</td>\n      <td>Taylor Swift, 0 songs</td>\n      <td>TranslationsPortuguêsEspañolTürkçeFrançais中文Ne...</td>\n      <td>https://genius.com/Taylor-swift-anti-hero-lyrics</td>\n      <td>8434253</td>\n      <td>Stats('unreviewed_annotations, concurrents, ho...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2022</td>\n      <td>10</td>\n      <td>Unholy</td>\n      <td>Sam Smith &amp; Kim Petras</td>\n      <td>Sam Smith &amp; Kim Petras, 0 songs</td>\n      <td>TranslationsFrançaisEspañolNederlandsDeutschال...</td>\n      <td>https://genius.com/Sam-smith-and-kim-petras-un...</td>\n      <td>8302862</td>\n      <td>Stats('unreviewed_annotations, concurrents, ho...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2022</td>\n      <td>11</td>\n      <td>The Christmas Song (Merry Christmas To You)</td>\n      <td>Nat King Cole</td>\n      <td>The Nat “King” Cole Trio, 0 songs</td>\n      <td>The Christmas Song (Merry Christmas to You) (O...</td>\n      <td>https://genius.com/The-nat-king-cole-trio-the-...</td>\n      <td>1717793</td>\n      <td>Stats('unreviewed_annotations, hot, pageviews')</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_song_data.tail(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "all_song_data.to_csv(\"all_songs_data.csv\")\n",
    "all_song_data.to_json(\"all_song_data.json\", orient='records')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_song_dataset = pd.read_csv(\"all_songs_data.csv\", index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(loaded_song_dataset.head())\n",
    "display(loaded_song_dataset.tail())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "songs_with_lyrics_dataset = loaded_song_dataset.dropna(subset=['Lyrics'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Understanding lyrics with T5 transformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* TODO: ADD BLEU/ROUGE evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL_NAME = 'igorktech/t5-base-en'\n",
    "SAVE_MODEL_NAME = 't5-base-en-explainer'\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device);\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "REPORT_STEPS = 1000\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "TASK_PREFIX = \"explain | \"\n",
    "MAX_INPUT = 64\n",
    "MAX_OUTPUT = 64\n",
    "# model.config.max_length = MAX_OUTPUT #not mandatory\n",
    "SAVE_TO_HUB = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for a, b in zip(data['train']['short'], data['train']['long']):\n",
    "    pairs.append([TASK_PREFIX + a, b])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.train()\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH', epoch)\n",
    "    random.shuffle(pairs)\n",
    "    for i in trange(0, int(len(pairs) / BATCH_SIZE)):\n",
    "        batch = pairs[i * BATCH_SIZE: (i + 1) * BATCH_SIZE]\n",
    "        x = tokenizer([p[0] for p in batch], return_tensors='pt', padding=\"longest\", \\\n",
    "                      max_length=MAX_INPUT, truncation=True).to(model.device)\n",
    "        y = tokenizer([p[1] for p in batch], return_tensors='pt', padding=\"longest\", \\\n",
    "                      max_length=MAX_OUTPUT, truncation=True, ).to(model.device)\n",
    "        y.input_ids[y.input_ids == 0] = -100\n",
    "        loss = model(\n",
    "            input_ids=x.input_ids,\n",
    "            attention_mask=x.attention_mask,\n",
    "            labels=y.input_ids,\n",
    "            decoder_attention_mask=y.attention_mask,\n",
    "            return_dict=True\n",
    "        ).loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        if i % REPORT_STEPS == 0:\n",
    "            print('step', i, 'loss', np.mean(losses[-REPORT_STEPS:]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if SAVE_TO_HUB:\n",
    "    notebook_login()\n",
    "    model.push_to_hub(SAVE_MODEL_NAME)\n",
    "    tokenizer.push_to_hub(SAVE_MODEL_NAME)\n",
    "else:\n",
    "    model.save_pretrained(SAVE_MODEL_NAME)\n",
    "    tokenizer.save_pretrained(SAVE_MODEL_NAME)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "\n",
    "def answer(x, **kwargs):\n",
    "    inputs = tokenizer(x, return_tensors='pt').to(model.device)\n",
    "    with torch.no_grad():\n",
    "        hypotheses = model.generate(**inputs, **kwargs)\n",
    "    return tokenizer.decode(hypotheses[0], skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('model: ', answer(TASK_PREFIX + 'What is love?'))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
